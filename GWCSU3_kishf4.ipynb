{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "GWCSU3_kishf4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMeaYDp0k4oZyFo8vGm8ZLv",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/balszeg/deep_learning_kishf4/blob/main/GWCSU3_kishf4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75Dulzs-KP5V"
      },
      "source": [
        "## Downloading the data ##\n",
        "To the download the data from Google Open Image Dataset I used the toolkit, which created for this reason. Cloning its git to the workspace."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgN-oAyV9jkv",
        "outputId": "402c0768-0645-47e5-e941-b29d2423031a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!git clone https://github.com/EscVM/OIDv4_ToolKit.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'OIDv4_ToolKit'...\n",
            "remote: Enumerating objects: 422, done.\u001b[K\n",
            "remote: Total 422 (delta 0), reused 0 (delta 0), pack-reused 422\u001b[K\n",
            "Receiving objects: 100% (422/422), 34.08 MiB | 38.14 MiB/s, done.\n",
            "Resolving deltas: 100% (146/146), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQxgxPgWK51k"
      },
      "source": [
        "Setting the right path for the toolkit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_6d0w9EYsRY",
        "outputId": "e32c545b-f55d-49fa-c551-56b3f9c874f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%cd /content/OIDv4_ToolKit/"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/OIDv4_ToolKit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDUsSclRK-a9"
      },
      "source": [
        "Installing the necessary required libraries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBrC4OCT9vV_",
        "outputId": "f26ed23c-c5a4-4ef2-e7b0-457c4c1cfdd3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip3 install -r requirements.txt"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 1)) (1.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (1.18.5)\n",
            "Collecting awscli\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/e4/abccbb6ade061cb7e14093ca2e352711f07800ff62049fd03849ba6a9e9d/awscli-1.18.175.tar.gz (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 5.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 5)) (1.24.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 7)) (4.41.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 9)) (4.1.2.30)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->-r requirements.txt (line 1)) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->-r requirements.txt (line 1)) (2.8.1)\n",
            "Collecting botocore==1.19.15\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f4/1d/bed1bb297abadc387d8328d88ac7612daa2d9f716bd83ec096ceb4a9f8bb/botocore-1.19.15-py2.py3-none-any.whl (6.7MB)\n",
            "\u001b[K     |████████████████████████████████| 6.7MB 27.6MB/s \n",
            "\u001b[?25hCollecting docutils<0.16,>=0.10\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/cd/a6aa959dca619918ccb55023b4cb151949c64d4d5d55b3f4ffd7eee0c6e8/docutils-0.15.2-py3-none-any.whl (547kB)\n",
            "\u001b[K     |████████████████████████████████| 552kB 53.2MB/s \n",
            "\u001b[?25hCollecting s3transfer<0.4.0,>=0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/79/e6afb3d8b0b4e96cefbdc690f741d7dd24547ff1f94240c997a26fa908d3/s3transfer-0.3.3-py2.py3-none-any.whl (69kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 10.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML<5.4,>=3.10 in /usr/local/lib/python3.6/dist-packages (from awscli->-r requirements.txt (line 3)) (3.13)\n",
            "Collecting colorama<0.4.4,>=0.2.5\n",
            "  Downloading https://files.pythonhosted.org/packages/c9/dc/45cdef1b4d119eb96316b3117e6d5708a08029992b2fee2c143c7a0a5cc5/colorama-0.4.3-py2.py3-none-any.whl\n",
            "Collecting rsa<=4.5.0,>=3.1.2\n",
            "  Downloading https://files.pythonhosted.org/packages/26/f8/8127fdda0294f044121d20aac7785feb810e159098447967a6103dedfb96/rsa-4.5-py2.py3-none-any.whl\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas->-r requirements.txt (line 1)) (1.15.0)\n",
            "Collecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<=4.5.0,>=3.1.2->awscli->-r requirements.txt (line 3)) (0.4.8)\n",
            "Building wheels for collected packages: awscli\n",
            "  Building wheel for awscli (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for awscli: filename=awscli-1.18.175-py2.py3-none-any.whl size=3400549 sha256=300e8ce07cae58151b36cc4457701081b343b4ca23f31481b576b66dbbb6c4d8\n",
            "  Stored in directory: /root/.cache/pip/wheels/7e/07/9a/29532a7d2b5d2d91266172cd863547f36780b3368c4ee740bd\n",
            "Successfully built awscli\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: botocore 1.19.15 has requirement urllib3<1.26,>=1.25.4; python_version != \"3.4\", but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: jmespath, botocore, docutils, s3transfer, colorama, rsa, awscli\n",
            "  Found existing installation: docutils 0.16\n",
            "    Uninstalling docutils-0.16:\n",
            "      Successfully uninstalled docutils-0.16\n",
            "  Found existing installation: rsa 4.6\n",
            "    Uninstalling rsa-4.6:\n",
            "      Successfully uninstalled rsa-4.6\n",
            "Successfully installed awscli-1.18.175 botocore-1.19.15 colorama-0.4.3 docutils-0.15.2 jmespath-0.10.0 rsa-4.5 s3transfer-0.3.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2sVOt_nLEZe"
      },
      "source": [
        "Calling the toolkit to download the 400-400 annoted images from 3 categories. These are the ball, camera and fish classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4TMbu-iajrB",
        "outputId": "b5cfed41-2853-4437-c4a4-d9647d2ca2e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!python3 main.py downloader -y --classes Ball --type_csv train --limit 400\n",
        "!python3 main.py downloader -y --classes Camera --type_csv train --limit 400\n",
        "!python3 main.py downloader -y --classes Fish --type_csv train --limit 400"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[92m\n",
            "\t\t   ___   _____  ______            _    _    \n",
            "\t\t .'   `.|_   _||_   _ `.         | |  | |   \n",
            "\t\t/  .-.  \\ | |    | | `. \\ _   __ | |__| |_  \n",
            "\t\t| |   | | | |    | |  | |[ \\ [  ]|____   _| \n",
            "\t\t\\  `-'  /_| |_  _| |_.' / \\ \\/ /     _| |_  \n",
            "\t\t `.___.'|_____||______.'   \\__/     |_____|\n",
            "\t\u001b[0m\n",
            "\u001b[92m\n",
            "             _____                    _                 _             \n",
            "            (____ \\                  | |               | |            \n",
            "             _   \\ \\ ___  _ _ _ ____ | | ___   ____  _ | | ____  ____ \n",
            "            | |   | / _ \\| | | |  _ \\| |/ _ \\ / _  |/ || |/ _  )/ ___)\n",
            "            | |__/ / |_| | | | | | | | | |_| ( ( | ( (_| ( (/ /| |    \n",
            "            |_____/ \\___/ \\____|_| |_|_|\\___/ \\_||_|\\____|\\____)_|    \n",
            "                                                          \n",
            "        \u001b[0m\n",
            "    [INFO] | Downloading Ball.\u001b[0m\n",
            "\u001b[91m   [ERROR] | Missing the class-descriptions-boxable.csv file.\u001b[0m\n",
            "\u001b[94m[DOWNLOAD] | Automatic download.\u001b[0m\n",
            "\r...72%, 0 MB, 68472 KB/s, 0 seconds passed\r...145%, 0 MB, 47661 KB/s, 0 seconds passed\n",
            "\u001b[94m[DOWNLOAD] | File class-descriptions-boxable.csv downloaded into OID/csv_folder/class-descriptions-boxable.csv.\u001b[0m\n",
            "\u001b[91m   [ERROR] | Missing the train-annotations-bbox.csv file.\u001b[0m\n",
            "\u001b[94m[DOWNLOAD] | Automatic download.\u001b[0m\n",
            "...100%, 1138 MB, 41902 KB/s, 27 seconds passed\n",
            "\u001b[94m[DOWNLOAD] | File train-annotations-bbox.csv downloaded into OID/csv_folder/train-annotations-bbox.csv.\u001b[0m\n",
            "\n",
            "\u001b[95mBall\u001b[0m\n",
            "    [INFO] | Downloading train images.\u001b[0m\n",
            "    [INFO] | [INFO] Found 3480 online images for train.\u001b[0m\n",
            "    [INFO] | Limiting to 400 images.\u001b[0m\n",
            "    [INFO] | Download of 400 images in train.\u001b[0m\n",
            "100% 400/400 [03:50<00:00,  1.73it/s]\n",
            "    [INFO] | Done!\u001b[0m\n",
            "    [INFO] | Creating labels for Ball of train.\u001b[0m\n",
            "    [INFO] | Labels creation completed.\u001b[0m\n",
            "\u001b[92m\n",
            "\t\t   ___   _____  ______            _    _    \n",
            "\t\t .'   `.|_   _||_   _ `.         | |  | |   \n",
            "\t\t/  .-.  \\ | |    | | `. \\ _   __ | |__| |_  \n",
            "\t\t| |   | | | |    | |  | |[ \\ [  ]|____   _| \n",
            "\t\t\\  `-'  /_| |_  _| |_.' / \\ \\/ /     _| |_  \n",
            "\t\t `.___.'|_____||______.'   \\__/     |_____|\n",
            "\t\u001b[0m\n",
            "\u001b[92m\n",
            "             _____                    _                 _             \n",
            "            (____ \\                  | |               | |            \n",
            "             _   \\ \\ ___  _ _ _ ____ | | ___   ____  _ | | ____  ____ \n",
            "            | |   | / _ \\| | | |  _ \\| |/ _ \\ / _  |/ || |/ _  )/ ___)\n",
            "            | |__/ / |_| | | | | | | | | |_| ( ( | ( (_| ( (/ /| |    \n",
            "            |_____/ \\___/ \\____|_| |_|_|\\___/ \\_||_|\\____|\\____)_|    \n",
            "                                                          \n",
            "        \u001b[0m\n",
            "    [INFO] | Downloading Camera.\u001b[0m\n",
            "\n",
            "\u001b[95mCamera\u001b[0m\n",
            "    [INFO] | Downloading train images.\u001b[0m\n",
            "    [INFO] | [INFO] Found 5037 online images for train.\u001b[0m\n",
            "    [INFO] | Limiting to 400 images.\u001b[0m\n",
            "    [INFO] | Download of 400 images in train.\u001b[0m\n",
            "100% 400/400 [03:41<00:00,  1.81it/s]\n",
            "    [INFO] | Done!\u001b[0m\n",
            "    [INFO] | Creating labels for Camera of train.\u001b[0m\n",
            "    [INFO] | Labels creation completed.\u001b[0m\n",
            "\u001b[92m\n",
            "\t\t   ___   _____  ______            _    _    \n",
            "\t\t .'   `.|_   _||_   _ `.         | |  | |   \n",
            "\t\t/  .-.  \\ | |    | | `. \\ _   __ | |__| |_  \n",
            "\t\t| |   | | | |    | |  | |[ \\ [  ]|____   _| \n",
            "\t\t\\  `-'  /_| |_  _| |_.' / \\ \\/ /     _| |_  \n",
            "\t\t `.___.'|_____||______.'   \\__/     |_____|\n",
            "\t\u001b[0m\n",
            "\u001b[92m\n",
            "             _____                    _                 _             \n",
            "            (____ \\                  | |               | |            \n",
            "             _   \\ \\ ___  _ _ _ ____ | | ___   ____  _ | | ____  ____ \n",
            "            | |   | / _ \\| | | |  _ \\| |/ _ \\ / _  |/ || |/ _  )/ ___)\n",
            "            | |__/ / |_| | | | | | | | | |_| ( ( | ( (_| ( (/ /| |    \n",
            "            |_____/ \\___/ \\____|_| |_|_|\\___/ \\_||_|\\____|\\____)_|    \n",
            "                                                          \n",
            "        \u001b[0m\n",
            "    [INFO] | Downloading Fish.\u001b[0m\n",
            "\n",
            "\u001b[95mFish\u001b[0m\n",
            "    [INFO] | Downloading train images.\u001b[0m\n",
            "    [INFO] | [INFO] Found 5434 online images for train.\u001b[0m\n",
            "    [INFO] | Limiting to 400 images.\u001b[0m\n",
            "    [INFO] | Download of 400 images in train.\u001b[0m\n",
            "100% 400/400 [03:32<00:00,  1.88it/s]\n",
            "    [INFO] | Done!\u001b[0m\n",
            "    [INFO] | Creating labels for Fish of train.\u001b[0m\n",
            "    [INFO] | Labels creation completed.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BoocDfWcLTZ0"
      },
      "source": [
        "Downloading the validation dataset with 100-100 annoted images from the mentioned categories."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEyOml4fZbrY",
        "outputId": "ce743d1c-4a74-4bc4-ddcd-9520f5065119",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!python3 main.py downloader -y --classes Ball --type_csv validation --limit 100\n",
        "!python3 main.py downloader -y --classes Camera --type_csv validation --limit 100\n",
        "!python3 main.py downloader -y --classes Fish --type_csv validation --limit 100"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[92m\n",
            "\t\t   ___   _____  ______            _    _    \n",
            "\t\t .'   `.|_   _||_   _ `.         | |  | |   \n",
            "\t\t/  .-.  \\ | |    | | `. \\ _   __ | |__| |_  \n",
            "\t\t| |   | | | |    | |  | |[ \\ [  ]|____   _| \n",
            "\t\t\\  `-'  /_| |_  _| |_.' / \\ \\/ /     _| |_  \n",
            "\t\t `.___.'|_____||______.'   \\__/     |_____|\n",
            "\t\u001b[0m\n",
            "\u001b[92m\n",
            "             _____                    _                 _             \n",
            "            (____ \\                  | |               | |            \n",
            "             _   \\ \\ ___  _ _ _ ____ | | ___   ____  _ | | ____  ____ \n",
            "            | |   | / _ \\| | | |  _ \\| |/ _ \\ / _  |/ || |/ _  )/ ___)\n",
            "            | |__/ / |_| | | | | | | | | |_| ( ( | ( (_| ( (/ /| |    \n",
            "            |_____/ \\___/ \\____|_| |_|_|\\___/ \\_||_|\\____|\\____)_|    \n",
            "                                                          \n",
            "        \u001b[0m\n",
            "    [INFO] | Downloading Ball.\u001b[0m\n",
            "\u001b[91m   [ERROR] | Missing the validation-annotations-bbox.csv file.\u001b[0m\n",
            "\u001b[94m[DOWNLOAD] | Automatic download.\u001b[0m\n",
            "...100%, 16 MB, 19525 KB/s, 0 seconds passed\n",
            "\u001b[94m[DOWNLOAD] | File validation-annotations-bbox.csv downloaded into OID/csv_folder/validation-annotations-bbox.csv.\u001b[0m\n",
            "\n",
            "\u001b[95mBall\u001b[0m\n",
            "    [INFO] | Downloading validation images.\u001b[0m\n",
            "    [INFO] | [INFO] Found 158 online images for validation.\u001b[0m\n",
            "    [INFO] | Limiting to 100 images.\u001b[0m\n",
            "    [INFO] | Download of 100 images in validation.\u001b[0m\n",
            "100% 100/100 [01:02<00:00,  1.60it/s]\n",
            "    [INFO] | Done!\u001b[0m\n",
            "    [INFO] | Creating labels for Ball of validation.\u001b[0m\n",
            "    [INFO] | Labels creation completed.\u001b[0m\n",
            "\u001b[92m\n",
            "\t\t   ___   _____  ______            _    _    \n",
            "\t\t .'   `.|_   _||_   _ `.         | |  | |   \n",
            "\t\t/  .-.  \\ | |    | | `. \\ _   __ | |__| |_  \n",
            "\t\t| |   | | | |    | |  | |[ \\ [  ]|____   _| \n",
            "\t\t\\  `-'  /_| |_  _| |_.' / \\ \\/ /     _| |_  \n",
            "\t\t `.___.'|_____||______.'   \\__/     |_____|\n",
            "\t\u001b[0m\n",
            "\u001b[92m\n",
            "             _____                    _                 _             \n",
            "            (____ \\                  | |               | |            \n",
            "             _   \\ \\ ___  _ _ _ ____ | | ___   ____  _ | | ____  ____ \n",
            "            | |   | / _ \\| | | |  _ \\| |/ _ \\ / _  |/ || |/ _  )/ ___)\n",
            "            | |__/ / |_| | | | | | | | | |_| ( ( | ( (_| ( (/ /| |    \n",
            "            |_____/ \\___/ \\____|_| |_|_|\\___/ \\_||_|\\____|\\____)_|    \n",
            "                                                          \n",
            "        \u001b[0m\n",
            "    [INFO] | Downloading Camera.\u001b[0m\n",
            "\n",
            "\u001b[95mCamera\u001b[0m\n",
            "    [INFO] | Downloading validation images.\u001b[0m\n",
            "    [INFO] | [INFO] Found 123 online images for validation.\u001b[0m\n",
            "    [INFO] | Limiting to 100 images.\u001b[0m\n",
            "    [INFO] | Download of 100 images in validation.\u001b[0m\n",
            "100% 100/100 [01:05<00:00,  1.53it/s]\n",
            "    [INFO] | Done!\u001b[0m\n",
            "    [INFO] | Creating labels for Camera of validation.\u001b[0m\n",
            "    [INFO] | Labels creation completed.\u001b[0m\n",
            "\u001b[92m\n",
            "\t\t   ___   _____  ______            _    _    \n",
            "\t\t .'   `.|_   _||_   _ `.         | |  | |   \n",
            "\t\t/  .-.  \\ | |    | | `. \\ _   __ | |__| |_  \n",
            "\t\t| |   | | | |    | |  | |[ \\ [  ]|____   _| \n",
            "\t\t\\  `-'  /_| |_  _| |_.' / \\ \\/ /     _| |_  \n",
            "\t\t `.___.'|_____||______.'   \\__/     |_____|\n",
            "\t\u001b[0m\n",
            "\u001b[92m\n",
            "             _____                    _                 _             \n",
            "            (____ \\                  | |               | |            \n",
            "             _   \\ \\ ___  _ _ _ ____ | | ___   ____  _ | | ____  ____ \n",
            "            | |   | / _ \\| | | |  _ \\| |/ _ \\ / _  |/ || |/ _  )/ ___)\n",
            "            | |__/ / |_| | | | | | | | | |_| ( ( | ( (_| ( (/ /| |    \n",
            "            |_____/ \\___/ \\____|_| |_|_|\\___/ \\_||_|\\____|\\____)_|    \n",
            "                                                          \n",
            "        \u001b[0m\n",
            "    [INFO] | Downloading Fish.\u001b[0m\n",
            "\n",
            "\u001b[95mFish\u001b[0m\n",
            "    [INFO] | Downloading validation images.\u001b[0m\n",
            "    [INFO] | [INFO] Found 340 online images for validation.\u001b[0m\n",
            "    [INFO] | Limiting to 100 images.\u001b[0m\n",
            "    [INFO] | Download of 100 images in validation.\u001b[0m\n",
            "100% 100/100 [01:05<00:00,  1.52it/s]\n",
            "    [INFO] | Done!\u001b[0m\n",
            "    [INFO] | Creating labels for Fish of validation.\u001b[0m\n",
            "    [INFO] | Labels creation completed.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vc4DcSa_LhQA"
      },
      "source": [
        "Lastly, downloading 100-100 images to testing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxB_Hjk6_SVx",
        "outputId": "970b2f3f-b842-4b9d-b5d7-2e9fe8db6360",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!python3 main.py downloader -y --classes Ball --type_csv test --limit 100\n",
        "!python3 main.py downloader -y --classes Camera --type_csv test --limit 100\n",
        "!python3 main.py downloader -y --classes Fish --type_csv test --limit 100"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[92m\n",
            "\t\t   ___   _____  ______            _    _    \n",
            "\t\t .'   `.|_   _||_   _ `.         | |  | |   \n",
            "\t\t/  .-.  \\ | |    | | `. \\ _   __ | |__| |_  \n",
            "\t\t| |   | | | |    | |  | |[ \\ [  ]|____   _| \n",
            "\t\t\\  `-'  /_| |_  _| |_.' / \\ \\/ /     _| |_  \n",
            "\t\t `.___.'|_____||______.'   \\__/     |_____|\n",
            "\t\u001b[0m\n",
            "\u001b[92m\n",
            "             _____                    _                 _             \n",
            "            (____ \\                  | |               | |            \n",
            "             _   \\ \\ ___  _ _ _ ____ | | ___   ____  _ | | ____  ____ \n",
            "            | |   | / _ \\| | | |  _ \\| |/ _ \\ / _  |/ || |/ _  )/ ___)\n",
            "            | |__/ / |_| | | | | | | | | |_| ( ( | ( (_| ( (/ /| |    \n",
            "            |_____/ \\___/ \\____|_| |_|_|\\___/ \\_||_|\\____|\\____)_|    \n",
            "                                                          \n",
            "        \u001b[0m\n",
            "    [INFO] | Downloading Ball.\u001b[0m\n",
            "\u001b[91m   [ERROR] | Missing the test-annotations-bbox.csv file.\u001b[0m\n",
            "\u001b[94m[DOWNLOAD] | Automatic download.\u001b[0m\n",
            "...100%, 49 MB, 39355 KB/s, 1 seconds passed\n",
            "\u001b[94m[DOWNLOAD] | File test-annotations-bbox.csv downloaded into OID/csv_folder/test-annotations-bbox.csv.\u001b[0m\n",
            "\n",
            "\u001b[95mBall\u001b[0m\n",
            "    [INFO] | Downloading test images.\u001b[0m\n",
            "    [INFO] | [INFO] Found 488 online images for test.\u001b[0m\n",
            "    [INFO] | Limiting to 100 images.\u001b[0m\n",
            "    [INFO] | Download of 100 images in test.\u001b[0m\n",
            "100% 100/100 [01:04<00:00,  1.55it/s]\n",
            "    [INFO] | Done!\u001b[0m\n",
            "    [INFO] | Creating labels for Ball of test.\u001b[0m\n",
            "    [INFO] | Labels creation completed.\u001b[0m\n",
            "\u001b[92m\n",
            "\t\t   ___   _____  ______            _    _    \n",
            "\t\t .'   `.|_   _||_   _ `.         | |  | |   \n",
            "\t\t/  .-.  \\ | |    | | `. \\ _   __ | |__| |_  \n",
            "\t\t| |   | | | |    | |  | |[ \\ [  ]|____   _| \n",
            "\t\t\\  `-'  /_| |_  _| |_.' / \\ \\/ /     _| |_  \n",
            "\t\t `.___.'|_____||______.'   \\__/     |_____|\n",
            "\t\u001b[0m\n",
            "\u001b[92m\n",
            "             _____                    _                 _             \n",
            "            (____ \\                  | |               | |            \n",
            "             _   \\ \\ ___  _ _ _ ____ | | ___   ____  _ | | ____  ____ \n",
            "            | |   | / _ \\| | | |  _ \\| |/ _ \\ / _  |/ || |/ _  )/ ___)\n",
            "            | |__/ / |_| | | | | | | | | |_| ( ( | ( (_| ( (/ /| |    \n",
            "            |_____/ \\___/ \\____|_| |_|_|\\___/ \\_||_|\\____|\\____)_|    \n",
            "                                                          \n",
            "        \u001b[0m\n",
            "    [INFO] | Downloading Camera.\u001b[0m\n",
            "\n",
            "\u001b[95mCamera\u001b[0m\n",
            "    [INFO] | Downloading test images.\u001b[0m\n",
            "    [INFO] | [INFO] Found 300 online images for test.\u001b[0m\n",
            "    [INFO] | Limiting to 100 images.\u001b[0m\n",
            "    [INFO] | Download of 100 images in test.\u001b[0m\n",
            "100% 100/100 [01:05<00:00,  1.53it/s]\n",
            "    [INFO] | Done!\u001b[0m\n",
            "    [INFO] | Creating labels for Camera of test.\u001b[0m\n",
            "    [INFO] | Labels creation completed.\u001b[0m\n",
            "\u001b[92m\n",
            "\t\t   ___   _____  ______            _    _    \n",
            "\t\t .'   `.|_   _||_   _ `.         | |  | |   \n",
            "\t\t/  .-.  \\ | |    | | `. \\ _   __ | |__| |_  \n",
            "\t\t| |   | | | |    | |  | |[ \\ [  ]|____   _| \n",
            "\t\t\\  `-'  /_| |_  _| |_.' / \\ \\/ /     _| |_  \n",
            "\t\t `.___.'|_____||______.'   \\__/     |_____|\n",
            "\t\u001b[0m\n",
            "\u001b[92m\n",
            "             _____                    _                 _             \n",
            "            (____ \\                  | |               | |            \n",
            "             _   \\ \\ ___  _ _ _ ____ | | ___   ____  _ | | ____  ____ \n",
            "            | |   | / _ \\| | | |  _ \\| |/ _ \\ / _  |/ || |/ _  )/ ___)\n",
            "            | |__/ / |_| | | | | | | | | |_| ( ( | ( (_| ( (/ /| |    \n",
            "            |_____/ \\___/ \\____|_| |_|_|\\___/ \\_||_|\\____|\\____)_|    \n",
            "                                                          \n",
            "        \u001b[0m\n",
            "    [INFO] | Downloading Fish.\u001b[0m\n",
            "\n",
            "\u001b[95mFish\u001b[0m\n",
            "    [INFO] | Downloading test images.\u001b[0m\n",
            "    [INFO] | [INFO] Found 914 online images for test.\u001b[0m\n",
            "    [INFO] | Limiting to 100 images.\u001b[0m\n",
            "    [INFO] | Download of 100 images in test.\u001b[0m\n",
            "100% 100/100 [01:04<00:00,  1.55it/s]\n",
            "    [INFO] | Done!\u001b[0m\n",
            "    [INFO] | Creating labels for Fish of test.\u001b[0m\n",
            "    [INFO] | Labels creation completed.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWY47PayL-aE"
      },
      "source": [
        "## Training ##\n",
        "Importing the necessary utility libraries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIoblCEx7BFy"
      },
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3,preprocess_input,decode_predictions\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras import backend as K\n",
        "import numpy as np"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Yt0dU8jMHck"
      },
      "source": [
        "Setting the training, validation datasets directories."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GiRFPWwC8xYV"
      },
      "source": [
        "base_dir = '/content/OIDv4_ToolKit/OID/Dataset'\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "train_ball_dir = os.path.join(train_dir, 'ball')\n",
        "train_camera_dir = os.path.join(train_dir, 'camera')\n",
        "train_fish_dir = os.path.join(train_dir, 'fish')\n",
        "validation_ball_dir = os.path.join(validation_dir, 'ball')\n",
        "validation_camera_dir = os.path.join(validation_dir, 'camera')\n",
        "validation_fish_dir = os.path.join(validation_dir, 'fish')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLN9Wy3LMPqO"
      },
      "source": [
        "Downloading the base model and modify it according to the task."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "baL58YzmCihu",
        "outputId": "0e47fccd-c7b9-4564-9177-ef66ae75defa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Downloading the pretrained model without the fully-connected layers\n",
        "base_model = InceptionV3(weights='imagenet', include_top=False)\n",
        "# After the last convolutional layer a global average pooling layer added for flattening\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "# Adding a feedfoward layer with ReLU activation\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "# Lastly, there will be 3 output of the network, for activation softmax is used\n",
        "predictions = Dense(3, activation='softmax')(x)\n",
        "# Creating the model\n",
        "model = Model(inputs=base_model.input, outputs=predictions)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LkneN-EwREy"
      },
      "source": [
        "First, the convolutional layers are freezed during the training, only the feedforward layers learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0p4Bfnz4DUhy"
      },
      "source": [
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Compiling the model, important to use the approriate loss type\n",
        "model.compile(optimizer='adam', metrics=['accuracy'],loss='categorical_crossentropy')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvekNsVWw6l6"
      },
      "source": [
        "On the images small changes were maden for data augmentation reasons."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q99fcAspDWbF",
        "outputId": "f1ec595f-bdaa-44c3-8100-1db9baf96cc1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Defining the images dimensions\n",
        "img_height=299\n",
        "img_width=299\n",
        "\n",
        "# Preparing and augmenting the images for training\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "train_generator = train_datagen.flow_from_directory(train_dir, target_size=(img_height, img_width), batch_size=10, class_mode='categorical')\n",
        "validation_generator = test_datagen.flow_from_directory(validation_dir, target_size=(img_height, img_width), batch_size=10, class_mode='categorical')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1200 images belonging to 3 classes.\n",
            "Found 300 images belonging to 3 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eulw5oM3D2AD",
        "outputId": "7628ba55-830c-4a1e-9e92-f245172c4a33",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Setting up a directory for the checkpoints and the callback function for saving them\n",
        "checkpoint_filepath = '/content/OIDv4_ToolKit/OID/Dataset/checkpoint'\n",
        "# The callback monitor the validation accuravy\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)\n",
        "\n",
        "# This funtion process both with the data augmentation and the network training \n",
        "model.fit_generator(train_generator,steps_per_epoch=100,validation_data=validation_generator,validation_steps=10,epochs=3,callbacks=[model_checkpoint_callback])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-12-b34e9859b78d>:11: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Epoch 1/3\n",
            "100/100 [==============================] - 39s 388ms/step - loss: 0.4855 - accuracy: 0.8650 - val_loss: 0.0802 - val_accuracy: 0.9700\n",
            "Epoch 2/3\n",
            "100/100 [==============================] - 37s 373ms/step - loss: 0.1232 - accuracy: 0.9640 - val_loss: 0.1244 - val_accuracy: 0.9600\n",
            "Epoch 3/3\n",
            "100/100 [==============================] - 37s 373ms/step - loss: 0.0744 - accuracy: 0.9750 - val_loss: 0.1112 - val_accuracy: 0.9600\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0eb255d278>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQ0hqrmr5CMT"
      },
      "source": [
        "Now freezing the upper layers and training the lower ones."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58TAx2KKEzGg"
      },
      "source": [
        "for layer in model.layers[:172]:\n",
        "       layer.trainable = False\n",
        "for layer in model.layers[172:]:\n",
        "       layer.trainable = True"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EofVGp0f5lOS"
      },
      "source": [
        "Compiling again the model with SGD and low learning rate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BrJFRotPFJUL"
      },
      "source": [
        "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), metrics=['accuracy'], loss='categorical_crossentropy')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnAakFYA55R9"
      },
      "source": [
        "Training again with lower layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEKY6VlwFMd4",
        "outputId": "77de0829-3cb9-49c6-ea01-493af2007f54",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.fit_generator(train_generator,steps_per_epoch=100,validation_data=validation_generator,validation_steps=10,epochs=3,callbacks=[model_checkpoint_callback])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "100/100 [==============================] - 39s 389ms/step - loss: 0.1887 - accuracy: 0.9290 - val_loss: 0.1056 - val_accuracy: 0.9700\n",
            "Epoch 2/3\n",
            "100/100 [==============================] - 38s 379ms/step - loss: 0.1599 - accuracy: 0.9460 - val_loss: 0.0876 - val_accuracy: 0.9600\n",
            "Epoch 3/3\n",
            "100/100 [==============================] - 38s 385ms/step - loss: 0.1504 - accuracy: 0.9440 - val_loss: 0.0596 - val_accuracy: 0.9900\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0ec4546b00>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRI5j1Nd81lF"
      },
      "source": [
        "Setting the test dataset for checking the training successfulness"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8p7vyE7805Z",
        "outputId": "2ea55e12-8814-43dd-8cdd-88e8f3458452",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "test_dir = os.path.join(base_dir, 'test')\n",
        "test_it = test_datagen.flow_from_directory(test_dir, target_size=(img_height, img_width), batch_size=10, class_mode='categorical')\n",
        "loss = model.evaluate(test_it, steps=100)\n",
        "#giving back the test accuracy and loss\n",
        "dict(zip(model.metrics_names, loss))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 300 images belonging to 3 classes.\n",
            " 30/100 [========>.....................] - ETA: 11s - loss: 0.0671 - accuracy: 0.9800WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 100 batches). You may need to use the repeat() function when building your dataset.\n",
            " 30/100 [========>.....................] - 5s 172ms/step - loss: 0.0671 - accuracy: 0.9800\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.9800000190734863, 'loss': 0.06714627146720886}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    }
  ]
}